{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7DiM6rmeM"
   },
   "source": [
    "# Pose Estimation\n",
    "Compare to PyTorch3D `Camera position optimization` sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "sEVdNGFwripM",
    "outputId": "27047061-a29b-4562-c164-c1288e24c266"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9mH5iVprQdZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# io utils\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "\n",
    "# 3D transformations functions\n",
    "from pytorch3d.transforms import so3_log_map, axis_angle_to_matrix, axis_angle_to_quaternion, quaternion_to_matrix\n",
    "\n",
    "# rendering components\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras, look_at_view_transform, \n",
    "    RasterizationSettings, MeshRenderer, MeshRasterizer,\n",
    "    HardPhongShader, PointLights, TexturesVertex\n",
    ")\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and generate views with PyTorch3D\n",
    "we're using the cow model from Keenan Crane, featured in the PyTorch3D tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWiPKnEIrQdd"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    torch_device = torch.device('cuda')\n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "mesh = load_objs_as_meshes(['data/cow.obj'], device=torch_device)\n",
    "\n",
    "# seems sane to fetch/estimate scale\n",
    "shape_scale = float(mesh.verts_list()[0].std(0).mean())*3 \n",
    "t_model_scale = np.ptp(np.array(mesh.verts_list()[0]),0).mean()\n",
    "print('model is {:.2f}x the size of the cow'.format(shape_scale/1.18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply the dataset generation code, taken from the PyTorch3D tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPlby75GrQdj"
   },
   "outputs": [],
   "source": [
    "image_size = (64,64)\n",
    "vfov_degrees = 60\n",
    "\n",
    "lights = PointLights(device=torch_device, location=[[0.0, 0.0, -3.0*shape_scale]])\n",
    "R, T = look_at_view_transform(dist=2.7*shape_scale, elev=60, azim=20)\n",
    "camera = FoVPerspectiveCameras(device=torch_device,znear=shape_scale, zfar=100*shape_scale, fov=vfov_degrees) \n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=image_size, \n",
    "    blur_radius=0.0, \n",
    "    faces_per_pixel=1, \n",
    ")\n",
    "\n",
    "renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(\n",
    "        cameras=camera, \n",
    "        raster_settings=raster_settings\n",
    "    ),\n",
    "    shader=HardPhongShader(\n",
    "        device=torch_device, \n",
    "        cameras=camera,\n",
    "        lights=lights\n",
    "    )\n",
    ")\n",
    "depth_raster =MeshRasterizer(\n",
    "    cameras=camera, \n",
    "    raster_settings=raster_settings\n",
    ")\n",
    "\n",
    "# Render the cow mesh \n",
    "target_image = np.squeeze(renderer(mesh, camera=camera, lights=lights, R=R, T=T))\n",
    "target_depth = np.squeeze(depth_raster(mesh, camera=camera, lights=lights, R=R, T=T).zbuf)\n",
    "target_depth[target_depth == -1] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Fuzzy Metaball renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import jax\n",
    "#jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import fm_render\n",
    "hyperparams = np.array([-13.69159107,  -2.67968404,   0.71023575,   6.36908448,  -5.42242999])\n",
    "NUM_MIXTURE = 40\n",
    "beta1 = jnp.float32(np.exp(hyperparams[0]))\n",
    "beta2 = jnp.float32(np.exp(hyperparams[1]))\n",
    "beta3 = jnp.float32(np.exp(hyperparams[2]))\n",
    "beta4 = jnp.float32(np.exp(hyperparams[3]))\n",
    "beta5 = jnp.float32(-np.exp(hyperparams[4]))\n",
    "\n",
    "render_jit = jax.jit(fm_render.render_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load a model of the cow. feel free to use the one reconstructed from silhouettes!\n",
    "with open('fuzzy_cow.pkl','rb') as fp:\n",
    "    mean,prec,weight_log = pickle.load(fp)\n",
    "weights = np.exp(weight_log)\n",
    "weights /= np.sum(weights)\n",
    "obj_scale = (weights[:,None] * mean).std(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pyt3dcamera(cam, image_size = image_size):\n",
    "    height, width = image_size\n",
    "    cx = width/2\n",
    "    cy = height/2\n",
    "    f = (height/np.tan((np.pi/180)*float(cam.fov[0])/2))*0.5\n",
    "    K = np.array([[f, 0, cx],[0,f,cy],[0,0,1]])\n",
    "    pixel_list = (np.array(np.meshgrid(width-np.arange(width),height-np.arange(height),[0]))[:,:,:,0]).reshape((3,-1)).T\n",
    "\n",
    "    camera_rays = (pixel_list - K[:,2])/np.diag(K)\n",
    "    camera_rays[:,-1] = 1\n",
    "    return jnp.array(camera_rays), jnp.array(so3_log_map(cam.R)[0]), jnp.array(-cam.R[0]@cam.T[0])\n",
    "# get the real camera\n",
    "camera_rays, axangl_true, trans_true = convert_pyt3dcamera(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add noise to pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_eps = 0.5\n",
    "rad_eps = (np.pi/180.0)*90 # range. so 90 is -45 to +45\n",
    "\n",
    "trans_err = np.random.randn(3)\n",
    "trans_err = trans_err/np.linalg.norm(trans_err)\n",
    "trans_err_r = np.random.rand()\n",
    "\n",
    "trans_err = trans_eps*trans_err*trans_err_r\n",
    "trans_shift = np.array(trans_true) - trans_err\n",
    "\n",
    "angles = np.random.randn(3)\n",
    "angles = angles/np.linalg.norm(angles)\n",
    "angle_mag = (np.random.rand()-0.5)*rad_eps\n",
    "R_I = np.array(axis_angle_to_matrix(torch.tensor(np.array(axangl_true))))\n",
    "R_R = np.array(axis_angle_to_matrix(torch.tensor(angles*angle_mag))).T\n",
    "R_C =  R_R @ R_I\n",
    "\n",
    "axangl_init = np.array(so3_log_map(torch.tensor(R_C[None])))[0]\n",
    "trans_init = np.array(R_R@np.array(trans_shift))\n",
    "\n",
    "rand_rot = abs(angle_mag*(180.0/np.pi))\n",
    "rand_trans = 100*(trans_err_r*trans_eps/t_model_scale)\n",
    "init_pose_err = np.sqrt(rand_rot*rand_trans)\n",
    "print('pose error of {:.1f}, random rotation of {:.1f} degrees and translation of {:.1f}%'.format(init_pose_err,rand_rot,rand_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.imshow(target_image)\n",
    "plt.title('image')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,2)\n",
    "vmin,vmax = np.nanmin(target_depth),np.nanmax(target_depth)\n",
    "plt.imshow(target_depth,vmin=vmin,vmax=vmax)\n",
    "plt.title('depth')\n",
    "plt.axis('off')\n",
    "est_depth, est_probs = render_jit(mean,prec,weight_log,camera_rays,axangl_init,trans_init,beta1/obj_scale,beta2/obj_scale,beta3)\n",
    "est_alpha = jnp.tanh(beta4*(jnp.exp(est_probs).sum(0)+beta5) )*0.5 + 0.5\n",
    "est_depth = np.array(est_depth)\n",
    "est_depth[est_alpha < 0.5] = np.nan\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(est_alpha.reshape(image_size),cmap='Greys')\n",
    "plt.title('FM alpha')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(est_depth.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('FM depth')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for camera pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_func(est_depth,est_alpha,true_depth,b4,b5):\n",
    "    cond = jnp.isnan(est_depth) | jnp.isnan(true_depth)\n",
    "    valid_depth_frac =   (~jnp.isnan(cond)).sum()/cond.shape[0]\n",
    "    avg_depth = jnp.where(cond,0,true_depth).mean()/valid_depth_frac\n",
    "    err = (est_depth - true_depth)/avg_depth\n",
    "    depth_loss =  (jnp.where(cond,0,err)**2).mean()\n",
    "\n",
    "    true_alpha = ~jnp.isnan(true_depth)\n",
    "    est_alpha = jnp.tanh(b4*(jnp.exp(est_alpha).sum(0)+b5) )*0.5 + 0.5\n",
    "    est_alpha = jnp.clip(est_alpha,1e-6,1-1e-6)\n",
    "    mask_loss = -((true_alpha * jnp.log(est_alpha)) + (~true_alpha)*jnp.log(1-est_alpha))\n",
    "    \n",
    "    loss_mul = true_alpha.sum()\n",
    "    term1 = depth_loss.mean()\n",
    "    term2 = mask_loss.mean()\n",
    "    return term1 + term2\n",
    "\n",
    "def objective(params,depth):\n",
    "    means,prec,weights_log,camera_rays,axangl,trans, beta1,beta2,beta3,beta4,beta5 = params\n",
    "    render_res = render_jit(means,prec,weights_log,camera_rays,axangl,trans,beta1,beta2,beta3)\n",
    "    return error_func(render_res[0],render_res[1],depth,beta4,beta5)\n",
    "grad_render3 = jax.jit(jax.value_and_grad(objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import optimizers\n",
    "from util import DegradeLR\n",
    "# Number of optimization steps\n",
    "# typically only needs a few hundred\n",
    "# and early exits\n",
    "Niter = 2000\n",
    "\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "# babysit learning rates\n",
    "adjust_lr = DegradeLR(1e-3,0.5,50,10,-1e-3)\n",
    "opt_init, opt_update, opt_params = optimizers.momentum(adjust_lr.step_func,0.9)\n",
    "\n",
    "\n",
    "tmp = [axangl_init,trans_init]\n",
    "opt_state = opt_init(tmp)\n",
    "\n",
    "losses = []\n",
    "jax_tdepth = jnp.array(target_depth.ravel())\n",
    "\n",
    "for i in loop:\n",
    "    p = opt_params(opt_state)\n",
    "\n",
    "    val,g = grad_render3([mean,prec,weight_log,camera_rays,p[0],p[1],beta1/obj_scale,beta2/obj_scale,beta3,beta4,beta5],jax_tdepth)\n",
    "\n",
    "    S = jnp.linalg.norm(p[1])\n",
    "    S2 = S*S\n",
    "    RS = jnp.linalg.norm(g[4])\n",
    "    TS = jnp.linalg.norm(g[5])*S\n",
    "    g1 = g[4]\n",
    "    g2 = g[5]*S2\n",
    "\n",
    "    opt_state = opt_update(i, [g1,g2], opt_state)\n",
    "\n",
    "    val = float(val)\n",
    "    losses.append(val)\n",
    "    if adjust_lr.add(val):\n",
    "        break\n",
    "    # Print the losses\n",
    "    loop.set_description(\"total_loss = %.3f\" % val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axangl_final, trans_final = opt_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('convergence plot')\n",
    "plt.plot(losses,marker='.',lw=0,ms=5,alpha=0.5)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,3,1)\n",
    "plt.imshow(target_image)\n",
    "plt.title('image')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,4)\n",
    "vmin,vmax = np.nanmin(target_depth),np.nanmax(target_depth)\n",
    "est_depth_true, est_prob_true = render_jit(mean,prec,weight_log,camera_rays,axangl_true,trans_true,beta1/obj_scale,beta2/obj_scale,beta3)\n",
    "est_alpha_true = jnp.tanh(beta4*(jnp.exp(est_prob_true).sum(0)+beta5) )*0.5 + 0.5\n",
    "est_depth_true = np.array(est_depth_true)\n",
    "est_depth_true[est_alpha_true < 0.5] = np.nan\n",
    "plt.imshow(est_depth_true.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('true pose')\n",
    "plt.axis('off')\n",
    "est_depth, est_probs = render_jit(mean,prec,weight_log,camera_rays,axangl_init,trans_init,beta1/obj_scale,beta2/obj_scale,beta3)\n",
    "est_alpha = jnp.tanh(beta4*(jnp.exp(est_probs).sum(0)+beta5) )*0.5 + 0.5\n",
    "est_depth = np.array(est_depth)\n",
    "est_depth[est_alpha < 0.5] = np.nan\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(est_alpha.reshape(image_size),cmap='Greys')\n",
    "plt.title('init FM alpha')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(est_depth.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('init FM depth')\n",
    "plt.axis('off')\n",
    "est_depth, est_probs = render_jit(mean,prec,weight_log,camera_rays,axangl_final,trans_final,beta1/obj_scale,beta2/obj_scale,beta3)\n",
    "est_alpha = jnp.tanh(beta4*(jnp.exp(est_probs).sum(0)+beta5) )*0.5 + 0.5\n",
    "est_depth = np.array(est_depth)\n",
    "est_depth[est_alpha < 0.5] = np.nan\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(est_alpha.reshape(image_size),cmap='Greys')\n",
    "plt.title('final FM alpha')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(est_depth.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('final FM depth')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('pose_est.pdf',facecolor=plt.gcf().get_facecolor(), edgecolor='none',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = axis_angle_to_quaternion(torch.tensor(np.array(axangl_true))[None])[0]\n",
    "q2 = axis_angle_to_quaternion(torch.tensor(np.array(axangl_final))[None])[0]\n",
    "e1 = torch.acos(torch.clamp((q1 * q2).sum(),-1,1))\n",
    "e2 = torch.acos(torch.clamp((-q1 * q2).sum(),-1,1))\n",
    "rot_err = float((180.0/np.pi)*2*min(e1,e2))\n",
    "\n",
    "R1 = np.array(quaternion_to_matrix(q1))\n",
    "R2 = np.array(quaternion_to_matrix(q2))\n",
    "t_norm = np.linalg.norm(R1.T@np.array(trans_true)-R2.T@np.array(trans_final))\n",
    "trans_err = 100*t_norm/t_model_scale\n",
    "\n",
    "pose_err = np.sqrt(rot_err*trans_err)\n",
    "print('init. pose error of {:04.1f} with rot. of {:04.1f} deg and trans. of {:04.1f}%'.format(init_pose_err,rand_rot,rand_trans))\n",
    "print('final pose error of {:04.1f} with rot. of {:04.1f} deg and trans. of {:04.1f}%'.format(pose_err,rot_err,trans_err))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anp_metadata": {
   "path": "fbsource/fbcode/vision/fair/pytorch3d/docs/tutorials/camera_position_optimization_with_differentiable_rendering.ipynb"
  },
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "colab": {
   "name": "camera_position_optimization_with_differentiable_rendering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "disseminate_notebook_info": {
   "backup_notebook_id": "1062179640844868"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
