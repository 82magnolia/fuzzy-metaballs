{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7DiM6rmeM"
   },
   "source": [
    "# Shape from Silhouette With Rays\n",
    "Compare to PyTorch3D `Fit a mesh with texture` sample. We only use a silhouette loss (PyTorch sample uses color, silhouette, edge, normal and laplacian loss terms). In our testing, this runs about 1,000x faster than the PyTorch  example on our CPU hardware, although it doesn't reconstruct color. \n",
    "\n",
    "This example differs from the other in that camera poses are implicitly stored in the camera rays data structure and there is no traditional pose optimization possible. However, here we can run simple (no batch) gradient descent on the entire dataset at once, which should be faster for large parallel computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util import image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import pyrender\n",
    "import transforms3d\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and generate views with TriMesh and PyRender\n",
    "we're using the cow model from Keenan Crane, featured in the PyTorch3D tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file = 'data/cow.obj'\n",
    "\n",
    "mesh_tri = trimesh.load(mesh_file)\n",
    "\n",
    "# seems sane to fetch/estimate scale\n",
    "shape_scale = float(mesh_tri.vertices.std(0).mean())*3\n",
    "center = np.array(mesh_tri.vertices.mean(0))\n",
    "print('model is {:.2f}x the size of the cow'.format(shape_scale/1.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_views = 20\n",
    "image_size = (64,64)\n",
    "vfov_degrees = 45\n",
    "# this balances covariance and mean optimization due to using Adam\n",
    "opt_shape_scale = 2.2\n",
    "shape_scale_mul = opt_shape_scale/shape_scale\n",
    "\n",
    "focal_length = 0.5*image_size[0]/np.tan((np.pi/180.0)*vfov_degrees/2)\n",
    "cx = (image_size[1]-1)/2\n",
    "cy = (image_size[0]-1)/2\n",
    "\n",
    "np.random.seed(42)\n",
    "rand_quats = np.random.randn(num_views,4)\n",
    "rand_quats = rand_quats/np.linalg.norm(rand_quats,axis=1,keepdims=True)\n",
    "\n",
    "mesh = pyrender.Mesh.from_trimesh(mesh_tri)\n",
    "\n",
    "ref_colors = []\n",
    "ref_depths = []\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh)\n",
    "\n",
    "trans = []\n",
    "for quat in rand_quats:\n",
    "\n",
    "    R = transforms3d.quaternions.quat2mat(quat)\n",
    "    loc = np.array([0,0,3*shape_scale]) @ R + center\n",
    "    trans.append(loc)\n",
    "    pose = np.vstack([np.vstack([R,loc]).T,np.array([0,0,0,1])])\n",
    "\n",
    "    light = pyrender.SpotLight(color=np.ones(3), intensity=50.0,\n",
    "                                innerConeAngle=np.pi/16.0,\n",
    "                                outerConeAngle=np.pi/6.0)\n",
    "    scene.add(light, pose=pose)\n",
    "\n",
    "    camera = pyrender.IntrinsicsCamera(focal_length,focal_length,cx,cy,znear=0.1*shape_scale,zfar=100*shape_scale)\n",
    "    scene.add(camera,pose=pose)\n",
    "\n",
    "    r = pyrender.OffscreenRenderer(image_size[1],image_size[0])\n",
    "    color, target_depth = r.render(scene)\n",
    "    target_depth[target_depth ==0] = np.nan\n",
    "    ref_colors.append(color)\n",
    "    ref_depths.append(target_depth)\n",
    "    \n",
    "    for node in list(scene.light_nodes):\n",
    "        scene.remove_node(node)\n",
    "        time.sleep(0.01)\n",
    "    for node in list(scene.camera_nodes):\n",
    "        scene.remove_node(node)\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(ref_colors, rows=4, cols=5, rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sil = (~np.isnan(ref_depths)).astype(np.float32)\n",
    "image_grid(ref_depths, rows=4, cols=5, rgb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Fuzzy Metaball renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import jax\n",
    "#jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import fm_render\n",
    "# when using stds, new settings,\n",
    "hyperparams = fm_render.hyperparams\n",
    "NUM_MIXTURE = 40\n",
    "beta2 = jnp.float32(np.exp(hyperparams[0]))\n",
    "beta3 = jnp.float32(np.exp(hyperparams[1]))\n",
    "\n",
    "gmm_init_scale = 1\n",
    "\n",
    "render_jit = jax.jit(fm_render.render_func_rays)\n",
    "shape_scale = float(mesh_tri.vertices[0].std(0).mean())*3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a Fuzzy Metaballs model from random blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mean = center+np.random.multivariate_normal(mean=[0,0,0],cov=1e-2*np.identity(3)*shape_scale,size=NUM_MIXTURE)\n",
    "rand_weight_log = jnp.log(np.ones(NUM_MIXTURE)/NUM_MIXTURE) + jnp.log(gmm_init_scale)\n",
    "rand_sphere_size = 30\n",
    "rand_prec = jnp.array([np.identity(3)*rand_sphere_size/shape_scale for _ in range(NUM_MIXTURE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "height, width = image_size\n",
    "K = np.array([[focal_length, 0, cx],[0,focal_length,cy],[0,0,1]])\n",
    "pixel_list = (np.array(np.meshgrid(np.arange(width),height-np.arange(height)-1,[0]))[:,:,:,0]).reshape((3,-1)).T\n",
    "camera_rays = (pixel_list - K[:,2])/np.diag(K)\n",
    "camera_rays[:,-1] = -1\n",
    "cameras_list = []\n",
    "for tran,quat in zip(trans,rand_quats):\n",
    "    R = transforms3d.quaternions.quat2mat(quat)\n",
    "    camera_rays2 = camera_rays @ R\n",
    "    t = np.tile(tran[None],(camera_rays2.shape[0],1))\n",
    "    \n",
    "    rays_trans = np.stack([camera_rays2,t],1)\n",
    "    cameras_list.append(rays_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import trimesh\n",
    "    import sklearn.mixture\n",
    "    pts = trimesh.sample.sample_surface_even(mesh_tri,10000)[0]\n",
    "    gmm = sklearn.mixture.GaussianMixture(NUM_MIXTURE)\n",
    "    gmm.fit(pts)\n",
    "    weights_log = np.log( gmm.weights_) + np.log(gmm_init_scale)\n",
    "    mean = gmm.means_\n",
    "    prec = gmm.precisions_cholesky_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_results_rand = []\n",
    "alpha_results_rand_depth = []\n",
    "for camera_rays in cameras_list:\n",
    "    est_depth, est_alpha, est_norm, est_w = render_jit(rand_mean,rand_prec,rand_weight_log,camera_rays,beta2/shape_scale,beta3)\n",
    "    alpha_results_rand.append(est_alpha.reshape(image_size))\n",
    "    est_depth = np.array(est_depth)\n",
    "    est_depth[est_alpha < 0.5] = np.nan\n",
    "    alpha_results_rand_depth.append(est_depth.reshape(image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(target_sil, rows=4, cols=5, rgb=False,cmap='Greys')\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "plt.suptitle('Reference Masks')\n",
    "image_grid(alpha_results_rand, rows=4, cols=5, rgb=False,cmap='Greys')\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "plt.suptitle('random init masks')\n",
    "image_grid(alpha_results_rand_depth, rows=4, cols=5, rgb=False)\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "plt.suptitle('SFS Fuzzy Metaball Initialization')\n",
    "#plt.savefig('sfs_init.pdf',facecolor=plt.gcf().get_facecolor(), edgecolor='none',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize from a random cloud to a shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params,true_alpha):\n",
    "    CLIP_ALPHA = 3e-8\n",
    "    means,prec,weights_log,camera_rays,beta2,beta3 = params\n",
    "    render_res = render_jit(means,prec,weights_log,camera_rays,beta2,beta3)\n",
    "\n",
    "    est_alpha = render_res[1]\n",
    "    est_alpha = jnp.clip(est_alpha,CLIP_ALPHA,1-CLIP_ALPHA)\n",
    "    mask_loss = - ((true_alpha * jnp.log(est_alpha)) + (1-true_alpha)*jnp.log(1-est_alpha))\n",
    "    return mask_loss.mean()\n",
    "grad_render3 = jax.jit(jax.value_and_grad(objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.example_libraries import optimizers\n",
    "from util import DegradeLR\n",
    "def irc(x): return int(round(x))\n",
    "\n",
    "all_cameras = jnp.array(cameras_list).reshape((-1,2,3))\n",
    "all_sils = jnp.array(target_sil.ravel()).astype(jnp.float32)\n",
    "\n",
    "# Number of optimization steps\n",
    "Nepochs = 10\n",
    "batch_size = 800\n",
    "Niter_epoch = int(np.ceil(len(all_cameras)/batch_size))\n",
    "\n",
    "vecM = jnp.array([[1,1,1],[shape_scale_mul,shape_scale_mul,shape_scale_mul]])[None]\n",
    "\n",
    "outer_loop = tqdm(range(Nepochs), desc=\" epoch\", position=0)\n",
    "\n",
    "adjust_lr = DegradeLR(1e-1,0.5,irc(Niter_epoch*0.4),irc(Niter_epoch*0.1),-1e-4)\n",
    "opt_init, opt_update, opt_params = optimizers.adam(adjust_lr.step_func)\n",
    "tmp = [rand_mean*shape_scale_mul,rand_prec/shape_scale_mul,rand_weight_log]\n",
    "opt_state = opt_init(tmp)\n",
    "\n",
    "\n",
    "rand_idx = np.arange(len(all_cameras))\n",
    "\n",
    "losses = []\n",
    "done = False\n",
    "\n",
    "for i in outer_loop:\n",
    "    np.random.shuffle(rand_idx)\n",
    "    rand_idx_jnp = jnp.array(rand_idx)\n",
    "    for j in tqdm(range(Niter_epoch), desc=\" iteration\", position=1, leave=False):\n",
    "        p = opt_params(opt_state)\n",
    "        idx = jax.lax.dynamic_slice(rand_idx_jnp,[j*batch_size],[batch_size])\n",
    "        val,g = grad_render3([p[0],p[1],p[2],vecM*all_cameras[idx],beta2/opt_shape_scale,beta3],all_sils[idx])   \n",
    "        opt_state = opt_update(i, g[:3], opt_state)\n",
    "\n",
    "        val = float(val)\n",
    "        losses.append(val)\n",
    "        outer_loop.set_description(\"total_loss = %.3f\" % val)\n",
    "        if adjust_lr.add(val):\n",
    "            done = True\n",
    "            break\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mean, final_prec, final_weight_log = opt_params(opt_state)\n",
    "final_mean /= shape_scale_mul\n",
    "final_prec *= shape_scale_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('convergence plot')\n",
    "plt.plot(losses,marker='.',lw=0,ms=5,alpha=0.5)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_results_final = []\n",
    "alpha_results_depth = []\n",
    "for camera_rays in cameras_list:\n",
    "    est_depth, est_alpha, est_norms, est_w = render_jit(final_mean,final_prec,final_weight_log,camera_rays,beta2/shape_scale,beta3)\n",
    "    alpha_results_final.append(est_alpha.reshape(image_size))\n",
    "    \n",
    "    est_depth = np.array(est_depth)\n",
    "    \n",
    "    est_depth[est_alpha < 0.5] = np.nan\n",
    "    alpha_results_depth.append(est_depth.reshape(image_size))\n",
    "image_grid(target_sil, rows=4, cols=5, rgb=False)\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "plt.suptitle('Reference Masks')\n",
    "\n",
    "image_grid(alpha_results_final, rows=4, cols=5, rgb=False)\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "plt.suptitle('Final masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.nanmin(np.array(ref_depths))\n",
    "vmax = np.nanmax(np.array(ref_depths))\n",
    "plt.imshow(alpha_results_depth[3],vmin=vmin,vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(ref_depths[3],vmin=vmin,vmax=vmax)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(alpha_results_depth, rows=4, cols=5, rgb=False,vmin=vmin,vmax=vmax)\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "plt.suptitle('SFS results')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('sfs_res.pdf',facecolor=plt.gcf().get_facecolor(), edgecolor='none',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "points_list = []\n",
    "colors_list = []\n",
    "num_sample = 5000\n",
    "\n",
    "for idx in range(len(final_mean)):\n",
    "    if final_weight_log[idx] > 0:  # final_weight_log keeps valid balls\n",
    "        prec = final_prec[idx]  # L^T\n",
    "        points_list.append(random.multivariate_normal(final_mean[idx], np.linalg.inv(prec.T @ prec), size=num_sample))\n",
    "        colors = np.stack([np.random.rand(3)] * num_sample, axis=0)\n",
    "        colors_list.append(colors)\n",
    "points = np.concatenate(points_list, axis=0)\n",
    "colors = np.concatenate(colors_list, axis=0)\n",
    "pcd = np.concatenate([points, colors], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.txt', pcd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
